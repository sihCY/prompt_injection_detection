{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmGLmw7LX3T1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import pandas as pd\n",
        "import random, time\n",
        "from babel.dates import format_date, format_datetime, format_time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import transformers, os\n",
        "from transformers import BertModel, AutoModel, AdamW, get_linear_schedule_with_warmup, BertTokenizer, BertForSequenceClassification"
      ],
      "metadata": {
        "id": "VLIqyzZ6ZDg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Classification Model/dataset.csv\")"
      ],
      "metadata": {
        "id": "NS_sTW20YQ8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "wTOocmknZXAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "6-94AjKcluaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['u', 'wa', 'ha', 'would', 'com'])\n",
        "# Get a string of the legitimate request text only\n",
        "data_text_fake = \",\".join(txt.lower() for txt in df.request[df.label==0])\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud(max_font_size=50,\n",
        "                      max_words=100,\n",
        "                      stopwords=stop_words,\n",
        "                      scale=5,\n",
        "                      background_color=\"white\").generate(data_text_fake)\n",
        "\n",
        "# Display the generated image:\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title('Most repeated words in all true texts',fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FX1RWYTolKFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a string of the malicious request text only\n",
        "data_text_fake = \",\".join(txt.lower() for txt in df.request[df.label==1])\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud(max_font_size=50,\n",
        "                      max_words=100,\n",
        "                      stopwords=stop_words,\n",
        "                      scale=5,\n",
        "                      background_color=\"white\").generate(data_text_fake)\n",
        "\n",
        "# Display the generated image:\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title('Most repeated words in all true texts',fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MNN56dVAmd3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "StzVbmI5kqIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the count of malicious and legitimate requests\n",
        "sns.countplot(x='label', data=df, palette = \"Set1\")"
      ],
      "metadata": {
        "id": "Pxa3OhiRZjZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import string\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = nlp.Defaults.stop_words\n",
        "punctuations = string.punctuation"
      ],
      "metadata": {
        "id": "rWZUY8WSrxdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    doc = nlp(sentence)\n",
        "   # print(doc)\n",
        "    # print(type(doc))\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() for word in doc ]\n",
        "    # print(mytokens)\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    sentence = \" \".join(mytokens)\n",
        "    # return preprocessed list of tokens\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "RhYHNIsR4eA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenize'] = df['request'].apply(spacy_tokenizer)"
      ],
      "metadata": {
        "id": "XFU7NjG_40-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "LzTdB9O75ube"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "vpX9nBEz5ozx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['embeddings'] = df['tokenize'].apply(model.encode)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "a3qDx3Ks6yR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['embeddings'].to_list()\n",
        "y = df['label'].to_list()"
      ],
      "metadata": {
        "id": "cykdiGGY5XGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)"
      ],
      "metadata": {
        "id": "CmBv3g2u7JfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LogisticRegression Model**"
      ],
      "metadata": {
        "id": "BffXhv92Cy2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "LR.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Xys1_v0A7RMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "predicted = LR.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
        "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "HGWQ7P2t7X3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Albert Model**"
      ],
      "metadata": {
        "id": "vZrgg4CNZzIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[torch]"
      ],
      "metadata": {
        "id": "WNGAb2r4Yw6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "d8s2GDeWZyuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "id": "iYqw-lEmaQwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import precision_recall_fscore_support, classification_report, roc_auc_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers.file_utils import cached_property\n",
        "from typing import Tuple\n"
      ],
      "metadata": {
        "id": "hB_xGyU-Kdef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"albert/albert-base-v2\"\n",
        "your_path = \"/content/drive/MyDrive/Classification Model/AlbertClassify-maliciousContent2\""
      ],
      "metadata": {
        "id": "oBmh69s5aSPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertForSequenceClassification, AlbertTokenizer\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
        "model = AlbertForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "cQlws1BrbKtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncodeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])"
      ],
      "metadata": {
        "id": "2legkC41chpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = EncodeDataset(tokenizer(X_train.request.tolist(),\n",
        "                                        max_length=64,\n",
        "                                        truncation=True,\n",
        "                                        padding='longest'), X_train.label.tolist())"
      ],
      "metadata": {
        "id": "Nmrl3178cqJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = EncodeDataset(tokenizer(X_valid.request.tolist(),\n",
        "                                       max_length=64,\n",
        "                                       truncation=True,\n",
        "                                       padding='longest'), X_valid.label.tolist())"
      ],
      "metadata": {
        "id": "X4ud2dKMcxuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = EncodeDataset(tokenizer(X_test.request.tolist(),\n",
        "                                       max_length=64,\n",
        "                                       truncation=True,\n",
        "                                       padding='longest'), X_test.label.tolist())"
      ],
      "metadata": {
        "id": "K-BvOo7adDHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "class TrAr(TrainingArguments):\n",
        "    @cached_property\n",
        "    def _setup_devices(self) -> Tuple[\"torch.device\", int]:\n",
        "        return device"
      ],
      "metadata": {
        "id": "Sm394J-Pd46t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "JQ-z6t6heA3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "9v_J4vP6eeKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=your_path+'/FINAL_VERS',   # output directory\n",
        "    num_train_epochs=3,\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=100,\n",
        "    learning_rate=2e-5,\n",
        "    save_steps=1000,\n",
        "    gradient_accumulation_steps=2\n",
        "    )"
      ],
      "metadata": {
        "id": "_60tDanne4ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "   args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=eval_dataset,           # evaluation dataset\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics  = compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "OcjXckiCgj55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Zy7CIYqvgbQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(test_dataset)"
      ],
      "metadata": {
        "id": "3U8N9veyg8do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def get_metrics(preds):\n",
        "    preds, labels = preds.predictions, preds.label_ids\n",
        "    #standard round approach\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    pr, rec, f, _ = precision_recall_fscore_support(labels, pred_flat, average='weighted')\n",
        "\n",
        "    print(\"precision\", pr)\n",
        "    print(\"recall\", rec)\n",
        "    print(\"fscore_weighted\", f)\n",
        "\n",
        "    #adjust threshold approach\n",
        "    preds_adj = np.array([[float(el1),float(el2)] for el1,el2 in preds])\n",
        "    preds_adj = softmax(preds_adj, axis = 1)\n",
        "    roc_auc = roc_auc_score(labels, preds_adj[:, 1])\n",
        "    print(\"roc_auc\", roc_auc)\n",
        "\n",
        "    all_metrcis = []\n",
        "    for threshold in [0.7,0.8,0.9, 1]:\n",
        "        metrcis = []\n",
        "        pred_labels = (preds_adj[:, 1] >= threshold).astype(int)\n",
        "        metrcis.append(threshold)\n",
        "        metrcis.append(round(f1_score(labels, pred_labels, average='weighted'),2))\n",
        "        metrcis.append(round(precision_score(labels, pred_labels),2))\n",
        "        metrcis.append(round(recall_score(labels, pred_labels),2))\n",
        "        metrcis.append(round(accuracy_score(labels, pred_labels),2))\n",
        "        all_metrcis.append(metrcis)\n",
        "\n",
        "    df_metrics = pd.DataFrame(data = all_metrcis, columns = ['threshold','f1','prec','rec','acc'])\n",
        "    df_metrics = df_metrics.sort_values(by='f1', ascending=False)\n",
        "\n",
        "    print(classification_report(labels, pred_flat))\n",
        "\n",
        "    print(df_metrics.head())\n",
        "\n",
        "    cm = confusion_matrix(labels, pred_flat, labels=[1,0])\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "\n",
        "    ax.xaxis.set_ticklabels(['Malicious', 'Legitimate'])\n",
        "    ax.yaxis.set_ticklabels(['Malicious', 'Legitimate'])\n",
        "\n",
        "    return f\n",
        "\n",
        "get_metrics(pred)"
      ],
      "metadata": {
        "id": "W_D_h_yfhj7Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}